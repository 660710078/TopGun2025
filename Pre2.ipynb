{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPYDLoYmp0MvSLxj5YXJ36J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/660710078/TopGun2025/blob/main/Pre2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Setup & Installation"
      ],
      "metadata": {
        "id": "6tXiHxOZQbxF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fSVxWYxPEry",
        "outputId": "a20cce8b-b3a4-4016-8aed-25da70dffb3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.222-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.222-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.222 ultralytics-thop-2.0.17\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python-headless) (2.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# ติดตั้ง libraries ที่จำเป็น\n",
        "!pip install ultralytics\n",
        "!pip install opencv-python-headless\n",
        "!pip install numpy pandas matplotlib\n",
        "\n",
        "# Import libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "import math\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Dataset Setup"
      ],
      "metadata": {
        "id": "kHxoROyTQjlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# กำหนด path\n",
        "base_path = '/content/drive/MyDrive/drone_dataset'\n",
        "yaml_path = f'{base_path}/data.yaml'\n",
        "\n",
        "# ตรวจสอบโครงสร้าง dataset\n",
        "!ls -la {base_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjpaqQbnPSnG",
        "outputId": "c67511c8-8754-4da4-8acd-bbfcdb62504c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 9\n",
            "-rw------- 1 root root  113 Oct 27 04:37 data.yaml\n",
            "drwx------ 2 root root 4096 Oct 27 03:59 train\n",
            "drwx------ 2 root root 4096 Oct 27 03:59 valid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Train YOLOv8 Model"
      ],
      "metadata": {
        "id": "HjR7C4vqQosj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# โหลด YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')  # n=nano, s=small, m=medium, l=large, x=xlarge\n",
        "\n",
        "# Train model\n",
        "results = model.train(\n",
        "    data=yaml_path,\n",
        "    epochs=50,  # ปรับตามความต้องการ\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    name='drone_detection',\n",
        "    patience=10,  # Early stopping\n",
        "    save=True,\n",
        "    plots=True\n",
        ")\n",
        "\n",
        "# บันทึก trained model\n",
        "model.save(f'{base_path}/best_drone_model.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czYgPpdWPYNP",
        "outputId": "e0803a61-51d8-4a1b-d802-399b55752f1c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 161.1MB/s 0.0s\n",
            "Ultralytics 8.3.222 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/drone_dataset/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=drone_detection, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/drone_detection, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 36.1MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 134.5MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.8±0.6 ms, read: 0.6±0.7 MB/s, size: 458.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/drone_dataset/train/labels.cache... 1012 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1012/1012 1.3Mit/s 0.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/drive/MyDrive/drone_dataset/train/images/pic_722.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.5±0.1 ms, read: 0.8±0.6 MB/s, size: 431.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/drone_dataset/valid/labels.cache... 347 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 347/347 60.5Kit/s 0.0s\n",
            "Plotting labels to /content/runs/detect/drone_detection/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/drone_detection\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      2.04G      1.431      1.996      1.611         10        640: 100% ━━━━━━━━━━━━ 64/64 1.3it/s 48.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 0.1it/s 2:38\n",
            "                   all        347        369      0.509      0.412      0.402      0.137\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      2.54G      1.454      1.704      1.616          8        640: 100% ━━━━━━━━━━━━ 64/64 2.2it/s 29.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.6it/s 4.3s\n",
            "                   all        347        369       0.35      0.336      0.233     0.0626\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      2.54G      1.493      1.572      1.633         11        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 31.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.7it/s 4.1s\n",
            "                   all        347        369       0.47      0.483      0.434      0.135\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      2.54G      1.476      1.457      1.641         10        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 29.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.9it/s 3.8s\n",
            "                   all        347        369      0.373      0.314      0.246     0.0993\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      2.55G      1.477      1.379      1.623          6        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 31.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.5it/s 4.3s\n",
            "                   all        347        369      0.528      0.512      0.434      0.214\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      2.57G      1.442      1.309      1.597         10        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 30.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.8it/s 4.0s\n",
            "                   all        347        369      0.681      0.585      0.642      0.272\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      2.57G      1.414      1.248      1.557         10        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 30.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.2it/s 5.1s\n",
            "                   all        347        369       0.64      0.686      0.638      0.317\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50      2.57G       1.41      1.178      1.556         10        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 31.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.5it/s 3.2s\n",
            "                   all        347        369       0.72      0.629      0.661      0.248\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      2.57G      1.359      1.131       1.52          9        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 31.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.2it/s 4.9s\n",
            "                   all        347        369      0.816      0.659      0.748      0.379\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      2.57G      1.345       1.12      1.513         10        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 31.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.7it/s 4.0s\n",
            "                   all        347        369      0.826      0.736      0.735      0.334\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      2.57G      1.313      1.079      1.469         11        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 29.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.4it/s 4.6s\n",
            "                   all        347        369      0.746      0.688      0.748      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      2.59G      1.316       1.07      1.482          9        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 31.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.4it/s 3.2s\n",
            "                   all        347        369      0.803      0.686      0.728      0.358\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50       2.6G      1.288      1.017      1.454          6        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 31.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.7it/s 4.0s\n",
            "                   all        347        369      0.818      0.794      0.816      0.425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50      2.61G      1.263     0.9778      1.448          8        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 31.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.0it/s 3.7s\n",
            "                   all        347        369      0.815      0.774      0.794      0.413\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      2.61G       1.27     0.9693      1.449         14        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 30.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.1it/s 3.6s\n",
            "                   all        347        369       0.84      0.751       0.84        0.4\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50      2.61G      1.291     0.9472      1.444         13        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 32.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.6it/s 4.2s\n",
            "                   all        347        369      0.849      0.765      0.834      0.383\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      2.61G      1.237     0.9315      1.418         11        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 29.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.0it/s 3.7s\n",
            "                   all        347        369      0.828      0.802      0.839      0.463\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50      2.61G       1.22     0.8927      1.412         13        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 30.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.0it/s 5.5s\n",
            "                   all        347        369      0.827      0.818      0.855      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      2.61G      1.207     0.8936      1.409          9        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 30.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.3it/s 3.4s\n",
            "                   all        347        369      0.866      0.824      0.873      0.487\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      2.61G      1.201     0.8599      1.405         10        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 32.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.1it/s 5.2s\n",
            "                   all        347        369      0.795        0.8      0.816      0.447\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      2.61G      1.191     0.8579      1.383         10        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 31.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.9it/s 3.8s\n",
            "                   all        347        369       0.87      0.832      0.888      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50      2.61G      1.181     0.8666      1.372         10        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 31.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 1.9it/s 5.6s\n",
            "                   all        347        369      0.824      0.811      0.882      0.453\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      2.61G      1.145     0.8202      1.357         13        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 31.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.1it/s 3.6s\n",
            "                   all        347        369      0.801      0.767      0.796       0.46\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      2.61G      1.154     0.8146      1.365         14        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 31.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 1.9it/s 5.7s\n",
            "                   all        347        369       0.84      0.813      0.846      0.454\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50      2.61G      1.141     0.8088       1.36         10        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 31.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.2it/s 3.4s\n",
            "                   all        347        369      0.781      0.827       0.83      0.443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      2.61G      1.127     0.7688      1.338         16        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 31.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 1.9it/s 5.7s\n",
            "                   all        347        369       0.88      0.774       0.88       0.51\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50      2.61G      1.126     0.7733      1.347         15        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 31.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.2it/s 3.5s\n",
            "                   all        347        369       0.84      0.823       0.85      0.469\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50      2.61G      1.108     0.7671      1.337         14        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 31.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.1it/s 5.2s\n",
            "                   all        347        369      0.796      0.806      0.827      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50      2.61G       1.11     0.7498      1.321         15        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 31.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.1it/s 3.6s\n",
            "                   all        347        369      0.896      0.864      0.909      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50      2.61G      1.098      0.733      1.324         11        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 32.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.0it/s 3.7s\n",
            "                   all        347        369      0.884      0.856      0.879       0.51\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50      2.61G      1.079     0.7297      1.312         11        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 31.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.0it/s 3.6s\n",
            "                   all        347        369      0.852      0.881        0.9      0.526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50      2.61G       1.09     0.7216      1.325         11        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 32.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.4it/s 3.3s\n",
            "                   all        347        369      0.875      0.872      0.918      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50      2.61G      1.042     0.7016      1.289         11        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 31.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.6it/s 4.2s\n",
            "                   all        347        369       0.89       0.88      0.912       0.55\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50      2.61G      1.069     0.6949      1.305          8        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 31.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.9it/s 3.8s\n",
            "                   all        347        369      0.899      0.841      0.903      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50      2.61G      1.045     0.6832      1.287          9        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 30.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.0it/s 5.5s\n",
            "                   all        347        369      0.862      0.861      0.894      0.558\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50      2.61G      1.055     0.6674      1.294         11        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 31.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.0it/s 3.7s\n",
            "                   all        347        369      0.888      0.875      0.908      0.526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50      2.61G      1.026     0.6566       1.27          8        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 32.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.7it/s 4.1s\n",
            "                   all        347        369      0.935      0.835      0.917      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50      2.61G      1.013     0.6428      1.257         16        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 32.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.9it/s 3.8s\n",
            "                   all        347        369      0.888      0.894      0.916      0.539\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50      2.61G      1.013     0.6418      1.259         12        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 31.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.7it/s 4.0s\n",
            "                   all        347        369      0.887      0.852      0.896      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50      2.61G     0.9864     0.6399      1.258         12        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 31.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.2it/s 5.1s\n",
            "                   all        347        369      0.918      0.878      0.929      0.558\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50      2.61G     0.8829      0.499      1.252          4        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 32.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.6it/s 4.2s\n",
            "                   all        347        369      0.891      0.883      0.918      0.561\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50      2.61G     0.8548      0.472      1.227          4        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 31.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.3it/s 3.3s\n",
            "                   all        347        369        0.9      0.851      0.913      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50      2.61G     0.8271     0.4673      1.218          4        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 30.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.8it/s 4.0s\n",
            "                   all        347        369      0.899      0.869      0.928      0.563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50      2.61G     0.8288     0.4532      1.212          4        640: 100% ━━━━━━━━━━━━ 64/64 2.0it/s 31.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.1it/s 3.5s\n",
            "                   all        347        369      0.908      0.881      0.924      0.562\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50      2.61G     0.7906     0.4316      1.174          4        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 30.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.0it/s 3.7s\n",
            "                   all        347        369      0.901      0.837      0.915      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50      2.61G     0.7788     0.4262      1.173          4        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 31.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.2it/s 3.5s\n",
            "                   all        347        369      0.938      0.858      0.933      0.572\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50      2.61G     0.7616     0.4298      1.156          4        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 30.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.3it/s 3.3s\n",
            "                   all        347        369      0.926      0.862      0.923      0.562\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50      2.61G     0.7623     0.4181      1.168          4        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 31.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.6it/s 4.2s\n",
            "                   all        347        369      0.906      0.851      0.917      0.566\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50      2.61G     0.7445     0.4078      1.149          4        640: 100% ━━━━━━━━━━━━ 64/64 2.2it/s 29.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 3.0it/s 3.7s\n",
            "                   all        347        369      0.886      0.878      0.911      0.552\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50      2.61G     0.7365     0.4034      1.144          4        640: 100% ━━━━━━━━━━━━ 64/64 2.1it/s 30.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 2.7it/s 4.1s\n",
            "                   all        347        369      0.905      0.873      0.918      0.557\n",
            "\n",
            "50 epochs completed in 0.551 hours.\n",
            "Optimizer stripped from /content/runs/detect/drone_detection/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs/detect/drone_detection/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs/detect/drone_detection/weights/best.pt...\n",
            "Ultralytics 8.3.222 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 1.7it/s 6.5s\n",
            "                   all        347        369      0.938      0.858      0.932      0.572\n",
            "Speed: 0.2ms preprocess, 2.2ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/drone_detection\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Image Processing Functions\n",
        "* ✅ เพิ่มความแม่นยำในการตรวจจับ\n",
        "* ✅ ทำงานได้ดีในสภาพแสงต่างๆ\n",
        "* ✅ ลด false positive\n",
        "\n"
      ],
      "metadata": {
        "id": "8Qs7sM9PQvlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DroneImageProcessor:\n",
        "    \"\"\"ประมวลผลภาพก่อนส่งเข้า YOLO\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def enhance_image(image):\n",
        "        \"\"\"\n",
        "        ปรับปรุงคุณภาพภาพ\n",
        "        - เพิ่ม contrast\n",
        "        - ลด noise\n",
        "        - ปรับความสว่าง\n",
        "        \"\"\"\n",
        "        # แปลงเป็น LAB color space\n",
        "        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "\n",
        "        # ใช้ CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "        l = clahe.apply(l)\n",
        "\n",
        "        # รวม channels กลับ\n",
        "        enhanced = cv2.merge([l, a, b])\n",
        "        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "        # ลด noise ด้วย bilateral filter\n",
        "        enhanced = cv2.bilateralFilter(enhanced, 9, 75, 75)\n",
        "\n",
        "        return enhanced\n",
        "\n",
        "    @staticmethod\n",
        "    def sharpen_image(image):\n",
        "        \"\"\"เพิ่มความคมชัด\"\"\"\n",
        "        kernel = np.array([[-1,-1,-1],\n",
        "                          [-1, 9,-1],\n",
        "                          [-1,-1,-1]])\n",
        "        sharpened = cv2.filter2D(image, -1, kernel)\n",
        "        return sharpened\n",
        "\n",
        "    @staticmethod\n",
        "    def adaptive_threshold_preprocessing(image):\n",
        "        \"\"\"สำหรับสภาพแสงที่ยาก\"\"\"\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        adaptive = cv2.adaptiveThreshold(\n",
        "            gray, 255,\n",
        "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "            cv2.THRESH_BINARY, 11, 2\n",
        "        )\n",
        "        return cv2.cvtColor(adaptive, cv2.COLOR_GRAY2BGR)"
      ],
      "metadata": {
        "id": "XjGWJSoFPeHf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Angle Detection System\n",
        "* คำนวณมุมจากตำแหน่งใน frame\n",
        "* ประมาณระยะทางจากขนาด bounding box\n",
        "* แสดงผลแบบเข้าใจง่าย"
      ],
      "metadata": {
        "id": "lv9P_QcgQy7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AngleDetector:\n",
        "    \"\"\"คำนวณมุมของ drone\"\"\"\n",
        "\n",
        "    def __init__(self, frame_height, frame_width):\n",
        "        self.frame_height = frame_height\n",
        "        self.frame_width = frame_width\n",
        "        self.center_y = frame_height // 2\n",
        "        self.center_x = frame_width // 2\n",
        "\n",
        "    def calculate_angle(self, bbox):\n",
        "        \"\"\"\n",
        "        คำนวณมุมราบและมุมเงย/ก้ม\n",
        "\n",
        "        Returns:\n",
        "            horizontal_angle: มุมราบ (-180 ถึง 180 องศา)\n",
        "            vertical_angle: มุมเงย/ก้ม (บวก=เงย, ลบ=ก้ม)\n",
        "        \"\"\"\n",
        "        x1, y1, x2, y2 = bbox\n",
        "\n",
        "        # หาจุดกึ่งกลาง bounding box\n",
        "        drone_center_x = (x1 + x2) / 2\n",
        "        drone_center_y = (y1 + y2) / 2\n",
        "\n",
        "        # คำนวณระยะห่างจากจุดกึ่งกลางเฟรม\n",
        "        delta_x = drone_center_x - self.center_x\n",
        "        delta_y = self.center_y - drone_center_y  # กลับทิศเพราะ y เพิ่มลงล่าง\n",
        "\n",
        "        # คำนวณมุมราบ (horizontal)\n",
        "        horizontal_angle = math.degrees(math.atan2(delta_x, self.frame_width/2)) * 2\n",
        "\n",
        "        # คำนวณมุมเงย/ก้ม (vertical)\n",
        "        vertical_angle = math.degrees(math.atan2(delta_y, self.frame_height/2)) * 2\n",
        "\n",
        "        # ประเมินมุมตาม position และขนาด\n",
        "        bbox_area = (x2 - x1) * (y2 - y1)\n",
        "        frame_area = self.frame_height * self.frame_width\n",
        "        size_ratio = bbox_area / frame_area\n",
        "\n",
        "        return {\n",
        "            'horizontal': round(horizontal_angle, 2),\n",
        "            'vertical': round(vertical_angle, 2),\n",
        "            'position': self._get_position(horizontal_angle, vertical_angle),\n",
        "            'distance_estimate': self._estimate_distance(size_ratio)\n",
        "        }\n",
        "\n",
        "    def _get_position(self, h_angle, v_angle):\n",
        "        \"\"\"บอกตำแหน่งของ drone\"\"\"\n",
        "        h_pos = \"กลาง\"\n",
        "        if h_angle < -20:\n",
        "            h_pos = \"ซ้าย\"\n",
        "        elif h_angle > 20:\n",
        "            h_pos = \"ขวา\"\n",
        "\n",
        "        v_pos = \"ระดับสายตา\"\n",
        "        if v_angle > 20:\n",
        "            v_pos = \"เงย\"\n",
        "        elif v_angle < -20:\n",
        "            v_pos = \"ก้ม\"\n",
        "\n",
        "        return f\"{v_pos} {h_pos}\"\n",
        "\n",
        "    def _estimate_distance(self, size_ratio):\n",
        "        \"\"\"ประมาณระยะทาง\"\"\"\n",
        "        if size_ratio > 0.15:\n",
        "            return \"ใกล้มาก\"\n",
        "        elif size_ratio > 0.08:\n",
        "            return \"ใกล้\"\n",
        "        elif size_ratio > 0.03:\n",
        "            return \"กลาง\"\n",
        "        else:\n",
        "            return \"ไกล\""
      ],
      "metadata": {
        "id": "QErjWdQ2Paax"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Tracking System with Centroid\n",
        "* คำนวณ centroid ของทุก detection\n",
        "* เปรียบเทียบกับ objects ที่ track อยู่\n",
        "* Match ด้วยระยะห่างที่ใกล้ที่สุด\n",
        "* เก็บ trajectory (เส้นทาง)"
      ],
      "metadata": {
        "id": "CpfuH_oAQ2mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CentroidTracker:\n",
        "    \"\"\"\n",
        "    ติดตาม drone ด้วย centroid tracking\n",
        "    - ใช้ระยะห่าง Euclidean เพื่อ match objects\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_disappeared=30):\n",
        "        self.next_object_id = 0\n",
        "        self.objects = {}  # {object_id: centroid}\n",
        "        self.disappeared = {}  # นับจำนวนครั้งที่หายไป\n",
        "        self.max_disappeared = max_disappeared\n",
        "        self.trajectory = {}  # เก็บเส้นทาง\n",
        "\n",
        "    def register(self, centroid):\n",
        "        \"\"\"ลงทะเบียน object ใหม่\"\"\"\n",
        "        self.objects[self.next_object_id] = centroid\n",
        "        self.disappeared[self.next_object_id] = 0\n",
        "        self.trajectory[self.next_object_id] = [centroid]\n",
        "        self.next_object_id += 1\n",
        "\n",
        "    def deregister(self, object_id):\n",
        "        \"\"\"ลบ object ที่หายไปนาน\"\"\"\n",
        "        del self.objects[object_id]\n",
        "        del self.disappeared[object_id]\n",
        "        del self.trajectory[object_id]\n",
        "\n",
        "    def update(self, detections):\n",
        "        \"\"\"\n",
        "        อัพเดท tracking\n",
        "\n",
        "        Args:\n",
        "            detections: list of bounding boxes [[x1,y1,x2,y2], ...]\n",
        "        \"\"\"\n",
        "        # ถ้าไม่มี detection\n",
        "        if len(detections) == 0:\n",
        "            for object_id in list(self.disappeared.keys()):\n",
        "                self.disappeared[object_id] += 1\n",
        "\n",
        "                if self.disappeared[object_id] > self.max_disappeared:\n",
        "                    self.deregister(object_id)\n",
        "\n",
        "            return self.objects\n",
        "\n",
        "        # คำนวณ centroid ของ detection ใหม่\n",
        "        input_centroids = np.zeros((len(detections), 2), dtype=\"int\")\n",
        "        for i, (x1, y1, x2, y2) in enumerate(detections):\n",
        "            cX = int((x1 + x2) / 2.0)\n",
        "            cY = int((y1 + y2) / 2.0)\n",
        "            input_centroids[i] = (cX, cY)\n",
        "\n",
        "        # ถ้ายังไม่มี object ที่ track\n",
        "        if len(self.objects) == 0:\n",
        "            for centroid in input_centroids:\n",
        "                self.register(centroid)\n",
        "        else:\n",
        "            # Match detection กับ existing objects\n",
        "            object_ids = list(self.objects.keys())\n",
        "            object_centroids = list(self.objects.values())\n",
        "\n",
        "            # คำนวณระยะห่าง\n",
        "            D = np.zeros((len(object_centroids), len(input_centroids)))\n",
        "            for i, obj_centroid in enumerate(object_centroids):\n",
        "                for j, input_centroid in enumerate(input_centroids):\n",
        "                    D[i, j] = np.linalg.norm(\n",
        "                        np.array(obj_centroid) - np.array(input_centroid)\n",
        "                    )\n",
        "\n",
        "            # หา minimum distance pairs\n",
        "            rows = D.min(axis=1).argsort()\n",
        "            cols = D.argmin(axis=1)[rows]\n",
        "\n",
        "            used_rows = set()\n",
        "            used_cols = set()\n",
        "\n",
        "            for (row, col) in zip(rows, cols):\n",
        "                if row in used_rows or col in used_cols:\n",
        "                    continue\n",
        "\n",
        "                # Update object\n",
        "                object_id = object_ids[row]\n",
        "                self.objects[object_id] = input_centroids[col]\n",
        "                self.disappeared[object_id] = 0\n",
        "                self.trajectory[object_id].append(tuple(input_centroids[col]))\n",
        "\n",
        "                # เก็บแค่ 50 จุดล่าสุด\n",
        "                if len(self.trajectory[object_id]) > 50:\n",
        "                    self.trajectory[object_id].pop(0)\n",
        "\n",
        "                used_rows.add(row)\n",
        "                used_cols.add(col)\n",
        "\n",
        "            # หา unused rows/cols\n",
        "            unused_rows = set(range(D.shape[0])) - used_rows\n",
        "            unused_cols = set(range(D.shape[1])) - used_cols\n",
        "\n",
        "            # จัดการ disappeared objects\n",
        "            for row in unused_rows:\n",
        "                object_id = object_ids[row]\n",
        "                self.disappeared[object_id] += 1\n",
        "\n",
        "                if self.disappeared[object_id] > self.max_disappeared:\n",
        "                    self.deregister(object_id)\n",
        "\n",
        "            # ลงทะเบียน detection ใหม่\n",
        "            for col in unused_cols:\n",
        "                self.register(input_centroids[col])\n",
        "\n",
        "        return self.objects"
      ],
      "metadata": {
        "id": "owpkOa8zPaXR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Video Processing & Visualization"
      ],
      "metadata": {
        "id": "q0GiVF3CQ7ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DroneDetectionSystem:\n",
        "    \"\"\"ระบบหลักสำหรับ detect และ track drone\"\"\"\n",
        "\n",
        "    def __init__(self, model_path, confidence=0.5):\n",
        "        self.model = YOLO(model_path)\n",
        "        self.confidence = confidence\n",
        "        self.processor = DroneImageProcessor()\n",
        "        self.tracker = CentroidTracker(max_disappeared=30)\n",
        "\n",
        "        # สำหรับ visualization\n",
        "        self.colors = {}\n",
        "\n",
        "    def get_color(self, object_id):\n",
        "        \"\"\"สร้างสีสำหรับแต่ละ object\"\"\"\n",
        "        if object_id not in self.colors:\n",
        "            self.colors[object_id] = (\n",
        "                np.random.randint(0, 255),\n",
        "                np.random.randint(0, 255),\n",
        "                np.random.randint(0, 255)\n",
        "            )\n",
        "        return self.colors[object_id]\n",
        "\n",
        "    def process_video(self, video_path, output_path=None,\n",
        "                     use_enhancement=True, show_trajectory=True):\n",
        "        \"\"\"\n",
        "        ประมวลผลวิดีโอ\n",
        "\n",
        "        Args:\n",
        "            video_path: path ของวิดีโอ\n",
        "            output_path: path สำหรับบันทึก (ถ้าไม่ระบุจะไม่บันทึก)\n",
        "            use_enhancement: ใช้ image processing หรือไม่\n",
        "            show_trajectory: แสดงเส้นทางหรือไม่\n",
        "        \"\"\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        if not cap.isOpened():\n",
        "            print(\"❌ ไม่สามารถเปิดวิดีโอได้\")\n",
        "            return\n",
        "\n",
        "        # รับข้อมูลวิดีโอ\n",
        "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        # สร้าง angle detector\n",
        "        angle_detector = AngleDetector(frame_height, frame_width)\n",
        "\n",
        "        # เตรียม video writer\n",
        "        writer = None\n",
        "        if output_path:\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            writer = cv2.VideoWriter(\n",
        "                output_path, fourcc, fps,\n",
        "                (frame_width, frame_height)\n",
        "            )\n",
        "\n",
        "        frame_count = 0\n",
        "        detection_count = 0\n",
        "\n",
        "        print(f\"🎬 เริ่มประมวลผลวิดีโอ...\")\n",
        "        print(f\"📊 ขนาด: {frame_width}x{frame_height} | FPS: {fps} | Frames: {total_frames}\")\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "            # Image enhancement (ถ้าเปิดใช้)\n",
        "            processed_frame = frame.copy()\n",
        "            if use_enhancement:\n",
        "                processed_frame = self.processor.enhance_image(processed_frame)\n",
        "\n",
        "            # Detect drones\n",
        "            results = self.model(processed_frame, conf=self.confidence, verbose=False)\n",
        "\n",
        "            # เก็บ detections\n",
        "            detections = []\n",
        "            detection_info = []\n",
        "\n",
        "            for result in results:\n",
        "                boxes = result.boxes\n",
        "                for box in boxes:\n",
        "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                    conf = float(box.conf[0])\n",
        "                    cls = int(box.cls[0])\n",
        "\n",
        "                    detections.append([x1, y1, x2, y2])\n",
        "                    detection_info.append({\n",
        "                        'bbox': [x1, y1, x2, y2],\n",
        "                        'confidence': conf,\n",
        "                        'class': cls\n",
        "                    })\n",
        "\n",
        "            # Update tracker\n",
        "            objects = self.tracker.update(detections)\n",
        "\n",
        "            # วาด visualization\n",
        "            for object_id, centroid in objects.items():\n",
        "                # หา bbox ที่ตรงกับ centroid\n",
        "                matched_info = None\n",
        "                min_dist = float('inf')\n",
        "\n",
        "                for info in detection_info:\n",
        "                    bbox = info['bbox']\n",
        "                    bbox_centroid = (\n",
        "                        (bbox[0] + bbox[2]) // 2,\n",
        "                        (bbox[1] + bbox[3]) // 2\n",
        "                    )\n",
        "                    dist = np.linalg.norm(\n",
        "                        np.array(centroid) - np.array(bbox_centroid)\n",
        "                    )\n",
        "                    if dist < min_dist:\n",
        "                        min_dist = dist\n",
        "                        matched_info = info\n",
        "\n",
        "                if matched_info is None:\n",
        "                    continue\n",
        "\n",
        "                detection_count += 1\n",
        "                color = self.get_color(object_id)\n",
        "                bbox = matched_info['bbox']\n",
        "                x1, y1, x2, y2 = bbox\n",
        "\n",
        "                # คำนวณมุม\n",
        "                angle_info = angle_detector.calculate_angle(bbox)\n",
        "\n",
        "                # วาด bounding box\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "                # วาด centroid\n",
        "                cv2.circle(frame, centroid, 5, color, -1)\n",
        "\n",
        "                # แสดง ID และข้อมูล\n",
        "                label = f\"ID:{object_id} | {matched_info['confidence']:.2f}\"\n",
        "                cv2.putText(frame, label, (x1, y1-10),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "                # แสดงมุม\n",
        "                angle_text = f\"H:{angle_info['horizontal']:.1f}° V:{angle_info['vertical']:.1f}°\"\n",
        "                cv2.putText(frame, angle_text, (x1, y2+20),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "                # แสดงตำแหน่ง\n",
        "                position_text = f\"{angle_info['position']} | {angle_info['distance_estimate']}\"\n",
        "                cv2.putText(frame, position_text, (x1, y2+40),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "                # วาด trajectory\n",
        "                if show_trajectory and object_id in self.tracker.trajectory:\n",
        "                    points = self.tracker.trajectory[object_id]\n",
        "                    for i in range(1, len(points)):\n",
        "                        cv2.line(frame, points[i-1], points[i], color, 2)\n",
        "\n",
        "            # แสดงข้อมูลทั่วไป\n",
        "            info_text = f\"Frame: {frame_count}/{total_frames} | Drones: {len(objects)}\"\n",
        "            cv2.putText(frame, info_text, (10, 30),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "            # วาดกากบาทตรงกลาง (จุดอ้างอิง)\n",
        "            center_x, center_y = frame_width // 2, frame_height // 2\n",
        "            cv2.drawMarker(frame, (center_x, center_y),\n",
        "                          (0, 255, 255), cv2.MARKER_CROSS, 20, 2)\n",
        "\n",
        "            # บันทึก frame\n",
        "            if writer:\n",
        "                writer.write(frame)\n",
        "\n",
        "            # แสดงความคืบหน้า\n",
        "            if frame_count % 30 == 0:\n",
        "                progress = (frame_count / total_frames) * 100\n",
        "                print(f\"⏳ ประมวลผล: {progress:.1f}% | Detections: {detection_count}\")\n",
        "\n",
        "        # ปิดทุกอย่าง\n",
        "        cap.release()\n",
        "        if writer:\n",
        "            writer.release()\n",
        "\n",
        "        print(f\"\\n✅ เสร็จสิ้น!\")\n",
        "        print(f\"📊 สถิติ:\")\n",
        "        print(f\"   - Total frames: {frame_count}\")\n",
        "        print(f\"   - Total detections: {detection_count}\")\n",
        "        print(f\"   - Unique drones tracked: {len(self.colors)}\")\n",
        "\n",
        "        if output_path:\n",
        "            print(f\"💾 บันทึกที่: {output_path}\")"
      ],
      "metadata": {
        "id": "KZd4ao3ZPaVE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Run Detection (Demo)"
      ],
      "metadata": {
        "id": "-N19brUGRAZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# โหลด trained model\n",
        "model_path = f'{base_path}/best_drone_model.pt'\n",
        "\n",
        "# หรือใช้ pretrained model (ถ้ายังไม่ train)\n",
        "# model_path = 'yolov8n.pt'\n",
        "\n",
        "# สร้างระบบ\n",
        "detector = DroneDetectionSystem(\n",
        "    model_path=model_path,\n",
        "    confidence=0.5  # ความมั่นใจขั้นต่ำ\n",
        ")\n",
        "\n",
        "# ทดสอบกับวิดีโอ\n",
        "video_path = '/content/cam0.mp4'\n",
        "output_path = '/content/drive/MyDrive/output_detected.mp4'\n",
        "\n",
        "detector.process_video(\n",
        "    video_path=video_path,\n",
        "    output_path=output_path,\n",
        "    use_enhancement=True,  # ใช้ image processing\n",
        "    show_trajectory=True    # แสดงเส้นทาง\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuCfcTxdPaSu",
        "outputId": "009742ba-d6ea-43c5-f42a-e3da7b3e9730"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎬 เริ่มประมวลผลวิดีโอ...\n",
            "📊 ขนาด: 1920x1080 | FPS: 29 | Frames: 5334\n",
            "⏳ ประมวลผล: 0.6% | Detections: 28\n",
            "⏳ ประมวลผล: 1.1% | Detections: 58\n",
            "⏳ ประมวลผล: 1.7% | Detections: 87\n",
            "⏳ ประมวลผล: 2.2% | Detections: 112\n",
            "⏳ ประมวลผล: 2.8% | Detections: 133\n",
            "⏳ ประมวลผล: 3.4% | Detections: 161\n",
            "⏳ ประมวลผล: 3.9% | Detections: 185\n",
            "⏳ ประมวลผล: 4.5% | Detections: 215\n",
            "⏳ ประมวลผล: 5.1% | Detections: 245\n",
            "⏳ ประมวลผล: 5.6% | Detections: 275\n",
            "⏳ ประมวลผล: 6.2% | Detections: 305\n",
            "⏳ ประมวลผล: 6.7% | Detections: 335\n",
            "⏳ ประมวลผล: 7.3% | Detections: 365\n",
            "⏳ ประมวลผล: 7.9% | Detections: 393\n",
            "⏳ ประมวลผล: 8.4% | Detections: 415\n",
            "⏳ ประมวลผล: 9.0% | Detections: 432\n",
            "⏳ ประมวลผล: 9.6% | Detections: 435\n",
            "⏳ ประมวลผล: 10.1% | Detections: 451\n",
            "⏳ ประมวลผล: 10.7% | Detections: 478\n",
            "⏳ ประมวลผล: 11.2% | Detections: 507\n",
            "⏳ ประมวลผล: 11.8% | Detections: 536\n",
            "⏳ ประมวลผล: 12.4% | Detections: 565\n",
            "⏳ ประมวลผล: 12.9% | Detections: 585\n",
            "⏳ ประมวลผล: 13.5% | Detections: 602\n",
            "⏳ ประมวลผล: 14.1% | Detections: 630\n",
            "⏳ ประมวลผล: 14.6% | Detections: 648\n",
            "⏳ ประมวลผล: 15.2% | Detections: 651\n",
            "⏳ ประมวลผล: 15.7% | Detections: 668\n",
            "⏳ ประมวลผล: 16.3% | Detections: 672\n",
            "⏳ ประมวลผล: 16.9% | Detections: 687\n",
            "⏳ ประมวลผล: 17.4% | Detections: 717\n",
            "⏳ ประมวลผล: 18.0% | Detections: 746\n",
            "⏳ ประมวลผล: 18.6% | Detections: 772\n",
            "⏳ ประมวลผล: 19.1% | Detections: 772\n",
            "⏳ ประมวลผล: 19.7% | Detections: 772\n",
            "⏳ ประมวลผล: 20.2% | Detections: 772\n",
            "⏳ ประมวลผล: 20.8% | Detections: 772\n",
            "⏳ ประมวลผล: 21.4% | Detections: 772\n",
            "⏳ ประมวลผล: 21.9% | Detections: 772\n",
            "⏳ ประมวลผล: 22.5% | Detections: 772\n",
            "⏳ ประมวลผล: 23.1% | Detections: 772\n",
            "⏳ ประมวลผล: 23.6% | Detections: 772\n",
            "⏳ ประมวลผล: 24.2% | Detections: 772\n",
            "⏳ ประมวลผล: 24.7% | Detections: 772\n",
            "⏳ ประมวลผล: 25.3% | Detections: 772\n",
            "⏳ ประมวลผล: 25.9% | Detections: 772\n",
            "⏳ ประมวลผล: 26.4% | Detections: 772\n",
            "⏳ ประมวลผล: 27.0% | Detections: 772\n",
            "⏳ ประมวลผล: 27.6% | Detections: 772\n",
            "⏳ ประมวลผล: 28.1% | Detections: 772\n",
            "⏳ ประมวลผล: 28.7% | Detections: 772\n",
            "⏳ ประมวลผล: 29.2% | Detections: 772\n",
            "⏳ ประมวลผล: 29.8% | Detections: 772\n",
            "⏳ ประมวลผล: 30.4% | Detections: 772\n",
            "⏳ ประมวลผล: 30.9% | Detections: 772\n",
            "⏳ ประมวลผล: 31.5% | Detections: 772\n",
            "⏳ ประมวลผล: 32.1% | Detections: 772\n",
            "⏳ ประมวลผล: 32.6% | Detections: 772\n",
            "⏳ ประมวลผล: 33.2% | Detections: 772\n",
            "⏳ ประมวลผล: 33.7% | Detections: 772\n",
            "⏳ ประมวลผล: 34.3% | Detections: 772\n",
            "⏳ ประมวลผล: 34.9% | Detections: 772\n",
            "⏳ ประมวลผล: 35.4% | Detections: 772\n",
            "⏳ ประมวลผล: 36.0% | Detections: 772\n",
            "⏳ ประมวลผล: 36.6% | Detections: 772\n",
            "⏳ ประมวลผล: 37.1% | Detections: 772\n",
            "⏳ ประมวลผล: 37.7% | Detections: 772\n",
            "⏳ ประมวลผล: 38.2% | Detections: 772\n",
            "⏳ ประมวลผล: 38.8% | Detections: 772\n",
            "⏳ ประมวลผล: 39.4% | Detections: 772\n",
            "⏳ ประมวลผล: 39.9% | Detections: 772\n",
            "⏳ ประมวลผล: 40.5% | Detections: 772\n",
            "⏳ ประมวลผล: 41.1% | Detections: 772\n",
            "⏳ ประมวลผล: 41.6% | Detections: 772\n",
            "⏳ ประมวลผล: 42.2% | Detections: 772\n",
            "⏳ ประมวลผล: 42.7% | Detections: 772\n",
            "⏳ ประมวลผล: 43.3% | Detections: 772\n",
            "⏳ ประมวลผล: 43.9% | Detections: 772\n",
            "⏳ ประมวลผล: 44.4% | Detections: 772\n",
            "⏳ ประมวลผล: 45.0% | Detections: 772\n",
            "⏳ ประมวลผล: 45.6% | Detections: 772\n",
            "⏳ ประมวลผล: 46.1% | Detections: 772\n",
            "⏳ ประมวลผล: 46.7% | Detections: 772\n",
            "⏳ ประมวลผล: 47.2% | Detections: 772\n",
            "⏳ ประมวลผล: 47.8% | Detections: 772\n",
            "⏳ ประมวลผล: 48.4% | Detections: 772\n",
            "⏳ ประมวลผล: 48.9% | Detections: 772\n",
            "⏳ ประมวลผล: 49.5% | Detections: 772\n",
            "⏳ ประมวลผล: 50.1% | Detections: 772\n",
            "⏳ ประมวลผล: 50.6% | Detections: 772\n",
            "⏳ ประมวลผล: 51.2% | Detections: 772\n",
            "⏳ ประมวลผล: 51.7% | Detections: 772\n",
            "⏳ ประมวลผล: 52.3% | Detections: 772\n",
            "⏳ ประมวลผล: 52.9% | Detections: 772\n",
            "⏳ ประมวลผล: 53.4% | Detections: 772\n",
            "⏳ ประมวลผล: 54.0% | Detections: 772\n",
            "⏳ ประมวลผล: 54.6% | Detections: 772\n",
            "⏳ ประมวลผล: 55.1% | Detections: 772\n",
            "⏳ ประมวลผล: 55.7% | Detections: 772\n",
            "⏳ ประมวลผล: 56.2% | Detections: 772\n",
            "⏳ ประมวลผล: 56.8% | Detections: 772\n",
            "⏳ ประมวลผล: 57.4% | Detections: 783\n",
            "⏳ ประมวลผล: 57.9% | Detections: 803\n",
            "⏳ ประมวลผล: 58.5% | Detections: 832\n",
            "⏳ ประมวลผล: 59.1% | Detections: 862\n",
            "⏳ ประมวลผล: 59.6% | Detections: 889\n",
            "⏳ ประมวลผล: 60.2% | Detections: 910\n",
            "⏳ ประมวลผล: 60.7% | Detections: 934\n",
            "⏳ ประมวลผล: 61.3% | Detections: 936\n",
            "⏳ ประมวลผล: 61.9% | Detections: 936\n",
            "⏳ ประมวลผล: 62.4% | Detections: 936\n",
            "⏳ ประมวลผล: 63.0% | Detections: 936\n",
            "⏳ ประมวลผล: 63.6% | Detections: 936\n",
            "⏳ ประมวลผล: 64.1% | Detections: 936\n",
            "⏳ ประมวลผล: 64.7% | Detections: 936\n",
            "⏳ ประมวลผล: 65.2% | Detections: 936\n",
            "⏳ ประมวลผล: 65.8% | Detections: 937\n",
            "⏳ ประมวลผล: 66.4% | Detections: 937\n",
            "⏳ ประมวลผล: 66.9% | Detections: 957\n",
            "⏳ ประมวลผล: 67.5% | Detections: 983\n",
            "⏳ ประมวลผล: 68.1% | Detections: 1010\n",
            "⏳ ประมวลผล: 68.6% | Detections: 1010\n",
            "⏳ ประมวลผล: 69.2% | Detections: 1010\n",
            "⏳ ประมวลผล: 69.7% | Detections: 1010\n",
            "⏳ ประมวลผล: 70.3% | Detections: 1010\n",
            "⏳ ประมวลผล: 70.9% | Detections: 1011\n",
            "⏳ ประมวลผล: 71.4% | Detections: 1011\n",
            "⏳ ประมวลผล: 72.0% | Detections: 1011\n",
            "⏳ ประมวลผล: 72.6% | Detections: 1011\n",
            "⏳ ประมวลผล: 73.1% | Detections: 1011\n",
            "⏳ ประมวลผล: 73.7% | Detections: 1011\n",
            "⏳ ประมวลผล: 74.2% | Detections: 1011\n",
            "⏳ ประมวลผล: 74.8% | Detections: 1011\n",
            "⏳ ประมวลผล: 75.4% | Detections: 1011\n",
            "⏳ ประมวลผล: 75.9% | Detections: 1011\n",
            "⏳ ประมวลผล: 76.5% | Detections: 1011\n",
            "⏳ ประมวลผล: 77.1% | Detections: 1011\n",
            "⏳ ประมวลผล: 77.6% | Detections: 1011\n",
            "⏳ ประมวลผล: 78.2% | Detections: 1011\n",
            "⏳ ประมวลผล: 78.7% | Detections: 1011\n",
            "⏳ ประมวลผล: 79.3% | Detections: 1011\n",
            "⏳ ประมวลผล: 79.9% | Detections: 1011\n",
            "⏳ ประมวลผล: 80.4% | Detections: 1011\n",
            "⏳ ประมวลผล: 81.0% | Detections: 1011\n",
            "⏳ ประมวลผล: 81.6% | Detections: 1036\n",
            "⏳ ประมวลผล: 82.1% | Detections: 1066\n",
            "⏳ ประมวลผล: 82.7% | Detections: 1091\n",
            "⏳ ประมวลผล: 83.2% | Detections: 1111\n",
            "⏳ ประมวลผล: 83.8% | Detections: 1119\n",
            "⏳ ประมวลผล: 84.4% | Detections: 1119\n",
            "⏳ ประมวลผล: 84.9% | Detections: 1119\n",
            "⏳ ประมวลผล: 85.5% | Detections: 1119\n",
            "⏳ ประมวลผล: 86.1% | Detections: 1119\n",
            "⏳ ประมวลผล: 86.6% | Detections: 1119\n",
            "⏳ ประมวลผล: 87.2% | Detections: 1119\n",
            "⏳ ประมวลผล: 87.7% | Detections: 1119\n",
            "⏳ ประมวลผล: 88.3% | Detections: 1119\n",
            "⏳ ประมวลผล: 88.9% | Detections: 1119\n",
            "⏳ ประมวลผล: 89.4% | Detections: 1119\n",
            "⏳ ประมวลผล: 90.0% | Detections: 1119\n",
            "⏳ ประมวลผล: 90.6% | Detections: 1119\n",
            "⏳ ประมวลผล: 91.1% | Detections: 1119\n",
            "⏳ ประมวลผล: 91.7% | Detections: 1119\n",
            "⏳ ประมวลผล: 92.2% | Detections: 1119\n",
            "⏳ ประมวลผล: 92.8% | Detections: 1119\n",
            "⏳ ประมวลผล: 93.4% | Detections: 1119\n",
            "⏳ ประมวลผล: 93.9% | Detections: 1119\n",
            "⏳ ประมวลผล: 94.5% | Detections: 1119\n",
            "⏳ ประมวลผล: 95.1% | Detections: 1119\n",
            "⏳ ประมวลผล: 95.6% | Detections: 1119\n",
            "⏳ ประมวลผล: 96.2% | Detections: 1119\n",
            "⏳ ประมวลผล: 96.7% | Detections: 1119\n",
            "⏳ ประมวลผล: 97.3% | Detections: 1119\n",
            "⏳ ประมวลผล: 97.9% | Detections: 1119\n",
            "⏳ ประมวลผล: 98.4% | Detections: 1119\n",
            "⏳ ประมวลผล: 99.0% | Detections: 1119\n",
            "⏳ ประมวลผล: 99.6% | Detections: 1119\n",
            "\n",
            "✅ เสร็จสิ้น!\n",
            "📊 สถิติ:\n",
            "   - Total frames: 5334\n",
            "   - Total detections: 1119\n",
            "   - Unique drones tracked: 6\n",
            "💾 บันทึกที่: /content/drive/MyDrive/output_detected.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 9: Evaluation & Visualization"
      ],
      "metadata": {
        "id": "owcZwlIlRDTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_sample_detections(image_folder, model, num_samples=4):\n",
        "    \"\"\"แสดงตัวอย่างการ detect\"\"\"\n",
        "    import glob\n",
        "    import random\n",
        "\n",
        "    images = glob.glob(f\"{image_folder}/*.jpg\") + glob.glob(f\"{image_folder}/*.png\")\n",
        "    samples = random.sample(images, min(num_samples, len(images)))\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    processor = DroneImageProcessor()\n",
        "\n",
        "    for idx, img_path in enumerate(samples):\n",
        "        img = cv2.imread(img_path)\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Enhance image\n",
        "        enhanced = processor.enhance_image(img)\n",
        "\n",
        "        # Detect\n",
        "        results = model(enhanced, conf=0.5)\n",
        "\n",
        "        # วาด results\n",
        "        for result in results:\n",
        "            boxes = result.boxes\n",
        "            for box in boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                conf = float(box.conf[0])\n",
        "\n",
        "                cv2.rectangle(img_rgb, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "                cv2.putText(img_rgb, f'{conf:.2f}', (x1, y1-10),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
        "\n",
        "        axes[idx].imshow(img_rgb)\n",
        "        axes[idx].axis('off')\n",
        "        axes[idx].set_title(f'Detection {idx+1}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{base_path}/sample_detections.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# เรียกใช้\n",
        "show_sample_detections(f'{base_path}/test/images', model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "eAN5PKC9PaQR",
        "outputId": "3fd68000-2650-4f6c-f53a-9234605e7a87"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABdIAAAXRCAYAAACaYm8JAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXwtJREFUeJzs3X9s3XW9+PFXV9YWIi3oXPfD4gQvogLb3FhvQWK4qTaBTPnjxilm211ELjgJrPde2YCtIrpyVcgSGS5MvPiH3E0JEOOWcbHXxaC7d3FjCV43CG66XWLLdrm0OLSF9vP9g2v51nWvcup6utHHIzl/9OPnc877mPfGa8+cfk5FURRFAAAAAAAAw5o03gsAAAAAAICTmZAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAImSQ/pPf/rTWLhwYcyYMSMqKiriscceG/Ga7du3x4c+9KGorq6O9773vfHggw+OYqkAAMCfmMsBAKB8Sg7pR48ejdmzZ8f69evf1PkHDhyIq666Kq644orYs2dP3HzzzXHttdfG448/XvJiAQCA15nLAQCgfCqKoihGfXFFRTz66KNx9dVXH/ecW265JbZs2RK//OUvB4996lOfipdeeim2bds22pcGAAD+j7kcAADG1mlj/QI7duyI5ubmIcdaWlri5ptvPu41vb290dvbO/jzwMBAvPjii/GOd7wjKioqxmqpAAAwakVRxMsvvxwzZsyISZNOvq8iMpcDADARjNVcPuYhvbOzM+rr64ccq6+vj56envjDH/4Qp59++jHXtLe3xx133DHWSwMAgBPu0KFD8a53vWu8l3EMczkAABPJiZ7Lxzykj8aqVauitbV18Ofu7u4455xz4tChQ1FbWzuOKwMAgOH19PREQ0NDnHnmmeO9lBPGXA4AwKlmrObyMQ/p06ZNi66uriHHurq6ora2dthPvUREVFdXR3V19THHa2trDewAAJzUTtZbnpjLAQCYSE70XD7mN29samqKjo6OIceeeOKJaGpqGuuXBgAA/o+5HAAARq/kkP773/8+9uzZE3v27ImIiAMHDsSePXvi4MGDEfH6r38uWbJk8Pzrr78+9u/fH1/84hdj3759cd9998X3v//9WLFixYl5BwAAMAGZywEAoHxKDum/+MUvYu7cuTF37tyIiGhtbY25c+fGmjVrIiLid7/73eDwHhHxnve8J7Zs2RJPPPFEzJ49O+6+++749re/HS0tLSfoLQAAwMRjLgcAgPKpKIqiGO9FjKSnpyfq6uqiu7vbvRgBADgpTYSZdSK8RwAATm1jNbOO+T3SAQAAAADgVCakAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgMaqQvn79+pg1a1bU1NREY2Nj7Ny5Mz1/3bp18b73vS9OP/30aGhoiBUrVsQf//jHUS0YAAB4nbkcAADKo+SQvnnz5mhtbY22trbYvXt3zJ49O1paWuKFF14Y9vyHHnooVq5cGW1tbbF379544IEHYvPmzXHrrbf+xYsHAICJylwOAADlU1EURVHKBY2NjXHJJZfEvffeGxERAwMD0dDQEDfeeGOsXLnymPO/8IUvxN69e6Ojo2Pw2D/8wz/Ef/7nf8aTTz457Gv09vZGb2/v4M89PT3R0NAQ3d3dUVtbW8pyAQCgLHp6eqKurq5sM6u5HAAAjjVWc3lJn0jv6+uLXbt2RXNz8xtPMGlSNDc3x44dO4a95tJLL41du3YN/prp/v37Y+vWrXHllVce93Xa29ujrq5u8NHQ0FDKMgEA4C3NXA4AAOV1WiknHzlyJPr7+6O+vn7I8fr6+ti3b9+w11xzzTVx5MiR+PCHPxxFUcRrr70W119/fforpKtWrYrW1tbBn//0yRcAAMBcDgAA5TaqLxstxfbt22Pt2rVx3333xe7du+ORRx6JLVu2xJ133nnca6qrq6O2tnbIAwAAGD1zOQAAjF5Jn0ifMmVKVFZWRldX15DjXV1dMW3atGGvWb16dSxevDiuvfbaiIi46KKL4ujRo3HdddfFbbfdFpMmjXnLBwCAtxRzOQAAlFdJ03JVVVXMmzdvyBcUDQwMREdHRzQ1NQ17zSuvvHLMUF5ZWRkRESV+zykAABDmcgAAKLeSPpEeEdHa2hpLly6N+fPnx4IFC2LdunVx9OjRWLZsWURELFmyJGbOnBnt7e0REbFw4cK45557Yu7cudHY2BjPPfdcrF69OhYuXDg4uAMAAKUxlwMAQPmUHNIXLVoUhw8fjjVr1kRnZ2fMmTMntm3bNvhFRwcPHhzySZfbb789Kioq4vbbb4/nn38+3vnOd8bChQvjq1/96ol7FwAAMMGYywEAoHwqilPg9zh7enqirq4uuru7fcERAAAnpYkws06E9wgAwKltrGZW3ygEAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAIDEqEL6+vXrY9asWVFTUxONjY2xc+fO9PyXXnopli9fHtOnT4/q6uo4//zzY+vWraNaMAAA8DpzOQAAlMdppV6wefPmaG1tjQ0bNkRjY2OsW7cuWlpa4plnnompU6cec35fX1989KMfjalTp8bDDz8cM2fOjN/+9rdx1llnnYj1AwDAhGQuBwCA8qkoiqIo5YLGxsa45JJL4t57742IiIGBgWhoaIgbb7wxVq5cecz5GzZsiK9//euxb9++mDx58qgW2dPTE3V1ddHd3R21tbWjeg4AABhL5Z5ZzeUAAHCssZpZS7q1S19fX+zatSuam5vfeIJJk6K5uTl27Ngx7DU//OEPo6mpKZYvXx719fVx4YUXxtq1a6O/v/+4r9Pb2xs9PT1DHgAAwOvM5QAAUF4lhfQjR45Ef39/1NfXDzleX18fnZ2dw16zf//+ePjhh6O/vz+2bt0aq1evjrvvvju+8pWvHPd12tvbo66ubvDR0NBQyjIBAOAtzVwOAADlNaovGy3FwMBATJ06Ne6///6YN29eLFq0KG677bbYsGHDca9ZtWpVdHd3Dz4OHTo01ssEAIC3NHM5AACMXklfNjplypSorKyMrq6uIce7urpi2rRpw14zffr0mDx5clRWVg4ee//73x+dnZ3R19cXVVVVx1xTXV0d1dXVpSwNAAAmDHM5AACUV0mfSK+qqop58+ZFR0fH4LGBgYHo6OiIpqamYa+57LLL4rnnnouBgYHBY88++2xMnz592GEdAADImcsBAKC8Sr61S2tra2zcuDG++93vxt69e+OGG26Io0ePxrJlyyIiYsmSJbFq1arB82+44YZ48cUX46abbopnn302tmzZEmvXro3ly5efuHcBAAATjLkcAADKp6Rbu0RELFq0KA4fPhxr1qyJzs7OmDNnTmzbtm3wi44OHjwYkya90ecbGhri8ccfjxUrVsTFF18cM2fOjJtuuiluueWWE/cuAABggjGXAwBA+VQURVGM9yJG0tPTE3V1ddHd3R21tbXjvRwAADjGRJhZJ8J7BADg1DZWM2vJt3YBAAAAAICJREgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBiVCF9/fr1MWvWrKipqYnGxsbYuXPnm7pu06ZNUVFREVdfffVoXhYAAPgzZnMAABh7JYf0zZs3R2tra7S1tcXu3btj9uzZ0dLSEi+88EJ63W9+85v4x3/8x7j88stHvVgAAOANZnMAACiPkkP6PffcE5/73Odi2bJl8YEPfCA2bNgQZ5xxRnznO9857jX9/f3xmc98Ju64444499xzR3yN3t7e6OnpGfIAAACGGuvZ3FwOAACvKymk9/X1xa5du6K5ufmNJ5g0KZqbm2PHjh3Hve7LX/5yTJ06NT772c++qddpb2+Purq6wUdDQ0MpywQAgLe8cszm5nIAAHhdSSH9yJEj0d/fH/X19UOO19fXR2dn57DXPPnkk/HAAw/Exo0b3/TrrFq1Krq7uwcfhw4dKmWZAADwlleO2dxcDgAArzttLJ/85ZdfjsWLF8fGjRtjypQpb/q66urqqK6uHsOVAQDAxDKa2dxcDgAArysppE+ZMiUqKyujq6tryPGurq6YNm3aMef/+te/jt/85jexcOHCwWMDAwOvv/Bpp8UzzzwT55133mjWDQAAE5rZHAAAyqekW7tUVVXFvHnzoqOjY/DYwMBAdHR0RFNT0zHnX3DBBfH000/Hnj17Bh8f//jH44orrog9e/a4xyIAAIyS2RwAAMqn5Fu7tLa2xtKlS2P+/PmxYMGCWLduXRw9ejSWLVsWERFLliyJmTNnRnt7e9TU1MSFF1445PqzzjorIuKY4wAAQGnM5gAAUB4lh/RFixbF4cOHY82aNdHZ2Rlz5syJbdu2DX7J0cGDB2PSpJI+6A4AAIyC2RwAAMqjoiiKYrwXMZKenp6oq6uL7u7uqK2tHe/lAADAMSbCzDoR3iMAAKe2sZpZfTwFAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABKjCunr16+PWbNmRU1NTTQ2NsbOnTuPe+7GjRvj8ssvj7PPPjvOPvvsaG5uTs8HAADePLM5AACMvZJD+ubNm6O1tTXa2tpi9+7dMXv27GhpaYkXXnhh2PO3b98en/70p+MnP/lJ7NixIxoaGuJjH/tYPP/883/x4gEAYCIzmwMAQHlUFEVRlHJBY2NjXHLJJXHvvfdGRMTAwEA0NDTEjTfeGCtXrhzx+v7+/jj77LPj3nvvjSVLlgx7Tm9vb/T29g7+3NPTEw0NDdHd3R21tbWlLBcAAMqip6cn6urqyjqzjvVsbi4HAOBUM1ZzeUmfSO/r64tdu3ZFc3PzG08waVI0NzfHjh073tRzvPLKK/Hqq6/G29/+9uOe097eHnV1dYOPhoaGUpYJAABveeWYzc3lAADwupJC+pEjR6K/vz/q6+uHHK+vr4/Ozs439Ry33HJLzJgxY8jA/+dWrVoV3d3dg49Dhw6VskwAAHjLK8dsbi4HAIDXnVbOF7vrrrti06ZNsX379qipqTnuedXV1VFdXV3GlQEAwMTyZmZzczkAALyupJA+ZcqUqKysjK6uriHHu7q6Ytq0aem13/jGN+Kuu+6KH//4x3HxxReXvlIAAGCQ2RwAAMqnpFu7VFVVxbx586Kjo2Pw2MDAQHR0dERTU9Nxr/va174Wd955Z2zbti3mz58/+tUCAAARYTYHAIByKvnWLq2trbF06dKYP39+LFiwINatWxdHjx6NZcuWRUTEkiVLYubMmdHe3h4REf/8z/8ca9asiYceeihmzZo1eL/Gt73tbfG2t73tBL4VAACYWMzmAABQHiWH9EWLFsXhw4djzZo10dnZGXPmzIlt27YNfsnRwYMHY9KkNz7o/q1vfSv6+vrib//2b4c8T1tbW3zpS1/6y1YPAAATmNkcAADKo6IoimK8FzGSnp6eqKuri+7u7qitrR3v5QAAwDEmwsw6Ed4jAACntrGaWUu6RzoAAAAAAEw0QjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAACJUYX09evXx6xZs6KmpiYaGxtj586d6fk/+MEP4oILLoiampq46KKLYuvWraNaLAAAMJTZHAAAxl7JIX3z5s3R2toabW1tsXv37pg9e3a0tLTECy+8MOz5P//5z+PTn/50fPazn42nnnoqrr766rj66qvjl7/85V+8eAAAmMjM5gAAUB4VRVEUpVzQ2NgYl1xySdx7770RETEwMBANDQ1x4403xsqVK485f9GiRXH06NH40Y9+NHjsr//6r2POnDmxYcOGN/WaPT09UVdXF93d3VFbW1vKcgEAoCzGY2Yt92xuLgcA4GQ3VjPraaWc3NfXF7t27YpVq1YNHps0aVI0NzfHjh07hr1mx44d0draOuRYS0tLPPbYY8d9nd7e3ujt7R38ubu7OyJe/z8BAABORn+aVUv8nMqolWM2N5cDAHCqGau5vKSQfuTIkejv74/6+vohx+vr62Pfvn3DXtPZ2Tns+Z2dncd9nfb29rjjjjuOOd7Q0FDKcgEAoOz+53/+J+rq6sb8dcoxm5vLAQA4VZ3oubykkF4uq1atGvJJmZdeeine/e53x8GDB8vyjxJOPT09PdHQ0BCHDh3ya8YMyx5hJPYII7FHGEl3d3ecc8458fa3v328l3LCmMsplb8rGYk9wkjsEUZijzCSsZrLSwrpU6ZMicrKyujq6hpyvKurK6ZNmzbsNdOmTSvp/IiI6urqqK6uPuZ4XV2dPyCkamtr7RFS9ggjsUcYiT3CSCZNmlSW1ynHbG4uZ7T8XclI7BFGYo8wEnuEkZzoubykZ6uqqop58+ZFR0fH4LGBgYHo6OiIpqamYa9pamoacn5ExBNPPHHc8wEAgJGZzQEAoHxKvrVLa2trLF26NObPnx8LFiyIdevWxdGjR2PZsmUREbFkyZKYOXNmtLe3R0TETTfdFB/5yEfi7rvvjquuuio2bdoUv/jFL+L+++8/se8EAAAmGLM5AACUR8khfdGiRXH48OFYs2ZNdHZ2xpw5c2Lbtm2DX1p08ODBIR+bv/TSS+Ohhx6K22+/PW699db4q7/6q3jsscfiwgsvfNOvWV1dHW1tbcP+WilE2COMzB5hJPYII7FHGMl47JFyz+b+HDASe4SR2COMxB5hJPYIIxmrPVJRFEVxQp8RAAAAAADeQsrzTUgAAAAAAHCKEtIBAAAAACAhpAMAAAAAQEJIBwAAAACAxEkT0tevXx+zZs2KmpqaaGxsjJ07d6bn/+AHP4gLLrggampq4qKLLoqtW7eWaaWMl1L2yMaNG+Pyyy+Ps88+O84+++xobm4ecU9x6iv175E/2bRpU1RUVMTVV189tgtkXJW6P1566aVYvnx5TJ8+Paqrq+P888/335q3uFL3yLp16+J973tfnH766dHQ0BArVqyIP/7xj2VaLeX205/+NBYuXBgzZsyIioqKeOyxx0a8Zvv27fGhD30oqqur473vfW88+OCDY77OE8FczkjM5YzEXM5IzOaMxGxOZtxm8+IksGnTpqKqqqr4zne+U/zXf/1X8bnPfa4466yziq6urmHP/9nPflZUVlYWX/va14pf/epXxe23315Mnjy5ePrpp8u8csql1D1yzTXXFOvXry+eeuqpYu/evcXf/d3fFXV1dcV///d/l3nllEupe+RPDhw4UMycObO4/PLLi0984hPlWSxlV+r+6O3tLebPn19ceeWVxZNPPlkcOHCg2L59e7Fnz54yr5xyKXWPfO973yuqq6uL733ve8WBAweKxx9/vJg+fXqxYsWKMq+cctm6dWtx2223FY888kgREcWjjz6anr9///7ijDPOKFpbW4tf/epXxTe/+c2isrKy2LZtW3kWPErmckZiLmck5nJGYjZnJGZzRjJes/lJEdIXLFhQLF++fPDn/v7+YsaMGUV7e/uw53/yk58srrrqqiHHGhsbi7//+78f03UyfkrdI3/utddeK84888ziu9/97lgtkXE2mj3y2muvFZdeemnx7W9/u1i6dKmB/S2s1P3xrW99qzj33HOLvr6+ci2RcVbqHlm+fHnxN3/zN0OOtba2FpdddtmYrpOTw5sZ1r/4xS8WH/zgB4ccW7RoUdHS0jKGK/vLmcsZibmckZjLGYnZnJGYzSlFOWfzcb+1S19fX+zatSuam5sHj02aNCmam5tjx44dw16zY8eOIedHRLS0tBz3fE5to9kjf+6VV16JV199Nd7+9reP1TIZR6PdI1/+8pdj6tSp8dnPfrYcy2ScjGZ//PCHP4ympqZYvnx51NfXx4UXXhhr166N/v7+ci2bMhrNHrn00ktj165dg79iun///ti6dWtceeWVZVkzJ79TcV41lzMSczkjMZczErM5IzGbMxZO1Mx62olc1GgcOXIk+vv7o76+fsjx+vr62Ldv37DXdHZ2Dnt+Z2fnmK2T8TOaPfLnbrnllpgxY8Yxf2h4axjNHnnyySfjgQceiD179pRhhYyn0eyP/fv3x7//+7/HZz7zmdi6dWs899xz8fnPfz5effXVaGtrK8eyKaPR7JFrrrkmjhw5Eh/+8IejKIp47bXX4vrrr49bb721HEvmFHC8ebWnpyf+8Ic/xOmnnz5OKzs+czkjMZczEnM5IzGbMxKzOWPhRM3m4/6JdBhrd911V2zatCkeffTRqKmpGe/lcBJ4+eWXY/HixbFx48aYMmXKeC+Hk9DAwEBMnTo17r///pg3b14sWrQobrvtttiwYcN4L42TxPbt22Pt2rVx3333xe7du+ORRx6JLVu2xJ133jneSwM4aZnL+XPmct4MszkjMZtTLuP+ifQpU6ZEZWVldHV1DTne1dUV06ZNG/aaadOmlXQ+p7bR7JE/+cY3vhF33XVX/PjHP46LL754LJfJOCp1j/z617+O3/zmN7Fw4cLBYwMDAxERcdppp8UzzzwT55133tgumrIZzd8h06dPj8mTJ0dlZeXgsfe///3R2dkZfX19UVVVNaZrprxGs0dWr14dixcvjmuvvTYiIi666KI4evRoXHfddXHbbbfFpEk+qzDRHW9era2tPSk/jR5hLmdk5nJGYi5nJGZzRmI2ZyycqNl83HdSVVVVzJs3Lzo6OgaPDQwMREdHRzQ1NQ17TVNT05DzIyKeeOKJ457PqW00eyQi4mtf+1rceeedsW3btpg/f345lso4KXWPXHDBBfH000/Hnj17Bh8f//jH44orrog9e/ZEQ0NDOZfPGBvN3yGXXXZZPPfcc4P/kIuIePbZZ2P69OkG9beg0eyRV1555ZiB/E//uHv9+26Y6E7FedVczkjM5YzEXM5IzOaMxGzOWDhhM2tJX006RjZt2lRUV1cXDz74YPGrX/2quO6664qzzjqr6OzsLIqiKBYvXlysXLly8Pyf/exnxWmnnVZ84xvfKPbu3Vu0tbUVkydPLp5++unxeguMsVL3yF133VVUVVUVDz/8cPG73/1u8PHyyy+P11tgjJW6R/7c0qVLi0984hNlWi3lVur+OHjwYHHmmWcWX/jCF4pnnnmm+NGPflRMnTq1+MpXvjJeb4ExVuoeaWtrK84888ziX//1X4v9+/cX//Zv/1acd955xSc/+cnxeguMsZdffrl46qmniqeeeqqIiOKee+4pnnrqqeK3v/1tURRFsXLlymLx4sWD5+/fv78444wzin/6p38q9u7dW6xfv76orKwstm3bNl5v4U0xlzMSczkjMZczErM5IzGbM5Lxms1PipBeFEXxzW9+szjnnHOKqqqqYsGCBcV//Md/DP5vH/nIR4qlS5cOOf/73/9+cf755xdVVVXFBz/4wWLLli1lXjHlVsoeefe7311ExDGPtra28i+csin175H/n4H9ra/U/fHzn/+8aGxsLKqrq4tzzz23+OpXv1q89tprZV415VTKHnn11VeLL33pS8V5551X1NTUFA0NDcXnP//54n//93/Lv3DK4ic/+cmws8Wf9sXSpUuLj3zkI8dcM2fOnKKqqqo499xzi3/5l38p+7pHw1zOSMzljMRczkjM5ozEbE5mvGbziqLwOw4AAAAAAHA8436PdAAAAAAAOJkJ6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAoOaT/9Kc/jYULF8aMGTOioqIiHnvssRGv2b59e3zoQx+K6urqeO973xsPPvjgKJYKAAD8ibkcAADKp+SQfvTo0Zg9e3asX7/+TZ1/4MCBuOqqq+KKK66IPXv2xM033xzXXnttPP744yUvFgAAeJ25HAAAyqeiKIpi1BdXVMSjjz4aV1999XHPueWWW2LLli3xy1/+cvDYpz71qXjppZdi27Zto31pAADg/5jLAQBgbJ021i+wY8eOaG5uHnKspaUlbr755uNe09vbG729vYM/DwwMxIsvvhjveMc7oqKiYqyWCgAAo1YURbz88ssxY8aMmDTp5PsqInM5AAATwVjN5WMe0js7O6O+vn7Isfr6+ujp6Yk//OEPcfrppx9zTXt7e9xxxx1jvTQAADjhDh06FO9617vGexnHMJcDADCRnOi5fMxD+misWrUqWltbB3/u7u6Oc845Jw4dOhS1tbXjuDIAABheT09PNDQ0xJlnnjneSzlhzOUAAJxqxmouH/OQPm3atOjq6hpyrKurK2pra4f91EtERHV1dVRXVx9zvLa21sAOAMBJ7WS95Ym5HACAieREz+VjfvPGpqam6OjoGHLsiSeeiKamprF+aQAA4P+YywEAYPRKDum///3vY8+ePbFnz56IiDhw4EDs2bMnDh48GBGv//rnkiVLBs+//vrrY//+/fHFL34x9u3bF/fdd198//vfjxUrVpyYdwAAABOQuRwAAMqn5JD+i1/8IubOnRtz586NiIjW1taYO3durFmzJiIifve73w0O7xER73nPe2LLli3xxBNPxOzZs+Puu++Ob3/729HS0nKC3gIAAEw85nIAACifiqIoivFexEh6enqirq4uuru73YsRAICT0kSYWSfCewQA4NQ2VjPrmN8jHQAAAAAATmVCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEqMK6evXr49Zs2ZFTU1NNDY2xs6dO9Pz161bF+973/vi9NNPj4aGhlixYkX88Y9/HNWCAQCA15nLAQCgPEoO6Zs3b47W1tZoa2uL3bt3x+zZs6OlpSVeeOGFYc9/6KGHYuXKldHW1hZ79+6NBx54IDZv3hy33nrrX7x4AACYqMzlAABQPiWH9HvuuSc+97nPxbJly+IDH/hAbNiwIc4444z4zne+M+z5P//5z+Oyyy6La665JmbNmhUf+9jH4tOf/vSIn5YBAACOz1wOAADlU1JI7+vri127dkVzc/MbTzBpUjQ3N8eOHTuGvebSSy+NXbt2DQ7o+/fvj61bt8aVV1553Nfp7e2Nnp6eIQ8AAOB15nIAACiv00o5+ciRI9Hf3x/19fVDjtfX18e+ffuGveaaa66JI0eOxIc//OEoiiJee+21uP7669NfIW1vb4877rijlKUBAMCEYS4HAIDyGtWXjZZi+/btsXbt2rjvvvti9+7d8cgjj8SWLVvizjvvPO41q1atiu7u7sHHoUOHxnqZAADwlmYuBwCA0SvpE+lTpkyJysrK6OrqGnK8q6srpk2bNuw1q1evjsWLF8e1114bEREXXXRRHD16NK677rq47bbbYtKkY1t+dXV1VFdXl7I0AACYMMzlAABQXiV9Ir2qqirmzZsXHR0dg8cGBgaio6Mjmpqahr3mlVdeOWYor6ysjIiIoihKXS8AAEx45nIAACivkj6RHhHR2toaS5cujfnz58eCBQti3bp1cfTo0Vi2bFlERCxZsiRmzpwZ7e3tERGxcOHCuOeee2Lu3LnR2NgYzz33XKxevToWLlw4OLgDAAClMZcDAED5lBzSFy1aFIcPH441a9ZEZ2dnzJkzJ7Zt2zb4RUcHDx4c8kmX22+/PSoqKuL222+P559/Pt75znfGwoUL46tf/eqJexcAADDBmMsBAKB8KopT4Pc4e3p6oq6uLrq7u6O2tna8lwMAAMeYCDPrRHiPAACc2sZqZi3pHukAAAAAADDRCOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEiMKqSvX78+Zs2aFTU1NdHY2Bg7d+5Mz3/ppZdi+fLlMX369Kiuro7zzz8/tm7dOqoFAwAArzOXAwBAeZxW6gWbN2+O1tbW2LBhQzQ2Nsa6deuipaUlnnnmmZg6deox5/f19cVHP/rRmDp1ajz88MMxc+bM+O1vfxtnnXXWiVg/AABMSOZyAAAon4qiKIpSLmhsbIxLLrkk7r333oiIGBgYiIaGhrjxxhtj5cqVx5y/YcOG+PrXvx779u2LyZMnv6nX6O3tjd7e3sGfe3p6oqGhIbq7u6O2traU5QIAQFn09PREXV1d2WZWczkAABxrrObykm7t0tfXF7t27Yrm5uY3nmDSpGhubo4dO3YMe80Pf/jDaGpqiuXLl0d9fX1ceOGFsXbt2ujv7z/u67S3t0ddXd3go6GhoZRlAgDAW5q5HAAAyqukkH7kyJHo7++P+vr6Icfr6+ujs7Nz2Gv2798fDz/8cPT398fWrVtj9erVcffdd8dXvvKV477OqlWroru7e/Bx6NChUpYJAABvaeZyAAAor5LvkV6qgYGBmDp1atx///1RWVkZ8+bNi+effz6+/vWvR1tb27DXVFdXR3V19VgvDQAAJgxzOQAAjF5JIX3KlClRWVkZXV1dQ453dXXFtGnThr1m+vTpMXny5KisrBw89v73vz86Ozujr68vqqqqRrFsAACYuMzlAABQXiXd2qWqqirmzZsXHR0dg8cGBgaio6Mjmpqahr3msssui+eeey4GBgYGjz377LMxffp0wzoAAIyCuRwAAMqrpJAeEdHa2hobN26M7373u7F379644YYb4ujRo7Fs2bKIiFiyZEmsWrVq8PwbbrghXnzxxbjpppvi2WefjS1btsTatWtj+fLlJ+5dAADABGMuBwCA8in5HumLFi2Kw4cPx5o1a6KzszPmzJkT27ZtG/yio4MHD8akSW/0+YaGhnj88cdjxYoVcfHFF8fMmTPjpptuiltuueXEvQsAAJhgzOUAAFA+FUVRFOO9iJH09PREXV1ddHd3R21t7XgvBwAAjjERZtaJ8B4BADi1jdXMWvKtXQAAAAAAYCIR0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAD/r727ja26PB84fkGxrUapGEJ5SJXA5th8IgPpqiPOpRmJRuXFIlEDjDjdIjOLzTZhOuvDZhlzhkyYRqZzL9zqXNQsSti0kywqCxkPCZsPiyLDLWuVZVKCGw/t7/+CWP8VuA6n0lOQzyc5L/x5/3ruk9zUi6+nPQAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAwopK9YsSImTpwYtbW10djYGOvWrTus+9rb22PYsGExe/bsgTwtAADwIWZzAAAYfGWH9MceeyxaWlqitbU1NmzYEOedd17MmjUr3n777fS+rVu3xre+9a2YOXPmgDcLAAB8wGwOAACVUXZIv/fee+O6666LBQsWxGc+85l44IEH4qSTToqHH374kPf09PTENddcE3fccUdMmjTpI20YAADYz2wOAACVUVZI37NnT6xfvz6am5s/+ALDh0dzc3OsXbv2kPfdeeedMWbMmLj22msP63l2794d3d3d/R4AAMAHKjGbm8sBAGC/skL69u3bo6enJ+rr6/tdr6+vj87OzoPe88ILL8RDDz0UK1euPOznaWtri7q6ur5HQ0NDOdsEAICPvUrM5uZyAADYb0AfNnq4du7cGXPnzo2VK1fG6NGjD/u+xYsXx44dO/oeb7311iDuEgAAPv4GMpubywEAYL8R5SwePXp0VFVVRVdXV7/rXV1dMXbs2APWv/HGG7F169a47LLL+q719vbuf+IRI+K1116LyZMnH3BfTU1N1NTUlLM1AAA4rlRiNjeXAwDAfmW9I726ujqmTZsWHR0dfdd6e3ujo6MjmpqaDlg/ZcqU2Lx5c2zatKnvcfnll8fFF18cmzZt8qOhAAAwQGZzAAConLLekR4R0dLSEvPnz4/p06fHjBkzYtmyZbFr165YsGBBRETMmzcvJkyYEG1tbVFbWxtnn312v/tPPfXUiIgDrgMAAOUxmwMAQGWUHdLnzJkT77zzTtx2223R2dkZU6dOjdWrV/d9yNG2bdti+PBB/dXrAABAmM0BAKBShhVFUQz1Jkrp7u6Ourq62LFjR4wcOXKotwMAAAc4HmbW4+E1AgBwbBusmdXbUwAAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgMaCQvmLFipg4cWLU1tZGY2NjrFu37pBrV65cGTNnzoxRo0bFqFGjorm5OV0PAAAcPrM5AAAMvrJD+mOPPRYtLS3R2toaGzZsiPPOOy9mzZoVb7/99kHXr1mzJq666qp4/vnnY+3atdHQ0BBf+tKX4p///OdH3jwAABzPzOYAAFAZw4qiKMq5obGxMc4///xYvnx5RET09vZGQ0ND3HjjjbFo0aKS9/f09MSoUaNi+fLlMW/evMN6zu7u7qirq4sdO3bEyJEjy9kuAABUxFDMrJWezc3lAAAc7QZrZi3rHel79uyJ9evXR3Nz8wdfYPjwaG5ujrVr1x7W13jvvfdi7969cdpppx1yze7du6O7u7vfAwAA+EAlZnNzOQAA7FdWSN++fXv09PREfX19v+v19fXR2dl5WF/j5ptvjvHjx/cb+D+sra0t6urq+h4NDQ3lbBMAAD72KjGbm8sBAGC/AX3Y6EAtWbIk2tvb48knn4za2tpDrlu8eHHs2LGj7/HWW29VcJcAAPDxdzizubkcAAD2G1HO4tGjR0dVVVV0dXX1u97V1RVjx45N773nnntiyZIl8dxzz8W5556brq2pqYmamppytgYAAMeVSszm5nIAANivrHekV1dXx7Rp06Kjo6PvWm9vb3R0dERTU9Mh71u6dGncddddsXr16pg+ffrAdwsAAESE2RwAACqprHekR0S0tLTE/PnzY/r06TFjxoxYtmxZ7Nq1KxYsWBAREfPmzYsJEyZEW1tbRET88Ic/jNtuuy1++ctfxsSJE/t+X+PJJ58cJ5988hF8KQAAcHwxmwMAQGWUHdLnzJkT77zzTtx2223R2dkZU6dOjdWrV/d9yNG2bdti+PAP3uh+//33x549e+LLX/5yv6/T2toat99++0fbPQAAHMfM5gAAUBnDiqIohnoTpXR3d0ddXV3s2LEjRo4cOdTbAQCAAxwPM+vx8BoBADi2DdbMWtbvSAcAAAAAgOONkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgISQDgAAAAAACSEdAAAAAAASQjoAAAAAACSEdAAAAAAASAjpAAAAAACQENIBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABAQkgHAAAAAICEkA4AAAAAAAkhHQAAAAAAEkI6AAAAAAAkhHQAAAAAAEgI6QAAAAAAkBDSAQAAAAAgIaQDAAAAAEBCSAcAAAAAgMSAQvqKFSti4sSJUVtbG42NjbFu3bp0/eOPPx5TpkyJ2traOOecc2LVqlUD2iwAANCf2RwAAAZf2SH9sccei5aWlmhtbY0NGzbEeeedF7NmzYq33377oOtfeumluOqqq+Laa6+NjRs3xuzZs2P27Nnxl7/85SNvHgAAjmdmcwAAqIxhRVEU5dzQ2NgY559/fixfvjwiInp7e6OhoSFuvPHGWLRo0QHr58yZE7t27Yqnn36679rnPve5mDp1ajzwwAMHfY7du3fH7t27+/55x44dcfrpp8dbb70VI0eOLGe7AABQEd3d3dHQ0BDvvvtu1NXVVeQ5B3s2N5cDAHCsGay5fEQ5i/fs2RPr16+PxYsX910bPnx4NDc3x9q1aw96z9q1a6OlpaXftVmzZsVTTz11yOdpa2uLO+6444DrDQ0N5WwXAAAq7t///ndFQnolZnNzOQAAx6ojPZeXFdK3b98ePT09UV9f3+96fX19vPrqqwe9p7Oz86DrOzs7D/k8ixcv7jfgv/vuu3HGGWfEtm3bKvbuHo4t7/+fJu+O4lCcEUpxRijFGaGU99+tfdppp1Xk+Soxm5vLKZfvlZTijFCKM0IpzgilDNZcXlZIr5Sampqoqak54HpdXZ0/IKRGjhzpjJByRijFGaEUZ4RShg8v+2OIjlrmcgbK90pKcUYoxRmhFGeEUo70XF7WVxs9enRUVVVFV1dXv+tdXV0xduzYg94zduzYstYDAAClmc0BAKByygrp1dXVMW3atOjo6Oi71tvbGx0dHdHU1HTQe5qamvqtj4h49tlnD7keAAAozWwOAACVU/avdmlpaYn58+fH9OnTY8aMGbFs2bLYtWtXLFiwICIi5s2bFxMmTIi2traIiPjmN78ZF110Ufz4xz+OSy+9NNrb2+PPf/5zPPjgg4f9nDU1NdHa2nrQHyuFCGeE0pwRSnFGKMUZoZShOCOVns39OaAUZ4RSnBFKcUYoxRmhlME6I8OKoijKvWn58uXxox/9KDo7O2Pq1Knxk5/8JBobGyMi4gtf+EJMnDgxHnnkkb71jz/+eNx6662xdevW+OQnPxlLly6NSy655Ii9CAAAOF6ZzQEAYPANKKQDAAAAAMDx4sh+dCkAAAAAAHzMCOkAAAAAAJAQ0gEAAAAAICGkAwAAAABA4qgJ6StWrIiJEydGbW1tNDY2xrp169L1jz/+eEyZMiVqa2vjnHPOiVWrVlVopwyVcs7IypUrY+bMmTFq1KgYNWpUNDc3lzxTHPvK/T7yvvb29hg2bFjMnj17cDfIkCr3fLz77ruxcOHCGDduXNTU1MSZZ57pvzUfc+WekWXLlsWnPvWpOPHEE6OhoSFuuumm+N///leh3VJpf/zjH+Oyyy6L8ePHx7Bhw+Kpp54qec+aNWvis5/9bNTU1MQnPvGJeOSRRwZ9n0eCuZxSzOWUYi6nFLM5pZjNyQzZbF4cBdrb24vq6uri4YcfLv76178W1113XXHqqacWXV1dB13/4osvFlVVVcXSpUuLl19+ubj11luLE044odi8eXOFd06llHtGrr766mLFihXFxo0bi1deeaX4yle+UtTV1RX/+Mc/KrxzKqXcM/K+N998s5gwYUIxc+bM4oorrqjMZqm4cs/H7t27i+nTpxeXXHJJ8cILLxRvvvlmsWbNmmLTpk0V3jmVUu4ZefTRR4uampri0UcfLd58883id7/7XTFu3LjipptuqvDOqZRVq1YVt9xyS/HEE08UEVE8+eST6fotW7YUJ510UtHS0lK8/PLLxX333VdUVVUVq1evrsyGB8hcTinmckoxl1OK2ZxSzOaUMlSz+VER0mfMmFEsXLiw7597enqK8ePHF21tbQddf+WVVxaXXnppv2uNjY3F1772tUHdJ0On3DPyYfv27StOOeWU4he/+MVgbZEhNpAzsm/fvuKCCy4ofvaznxXz5883sH+MlXs+7r///mLSpEnFnj17KrVFhli5Z2ThwoXFF7/4xX7XWlpaigsvvHBQ98nR4XCG9e985zvFWWed1e/anDlzilmzZg3izj46czmlmMspxVxOKWZzSjGbU45KzuZD/qtd9uzZE+vXr4/m5ua+a8OHD4/m5uZYu3btQe9Zu3Ztv/UREbNmzTrkeo5tAzkjH/bee+/F3r1747TTThusbTKEBnpG7rzzzhgzZkxce+21ldgmQ2Qg5+O3v/1tNDU1xcKFC6O+vj7OPvvsuPvuu6Onp6dS26aCBnJGLrjggli/fn3fj5hu2bIlVq1aFZdccklF9szR71icV83llGIupxRzOaWYzSnFbM5gOFIz64gjuamB2L59e/T09ER9fX2/6/X19fHqq68e9J7Ozs6Dru/s7By0fTJ0BnJGPuzmm2+O8ePHH/CHho+HgZyRF154IR566KHYtGlTBXbIUBrI+diyZUv84Q9/iGuuuSZWrVoVr7/+etxwww2xd+/eaG1trcS2qaCBnJGrr746tm/fHp///OejKIrYt29ffP3rX4/vfve7ldgyx4BDzavd3d3x3//+N0488cQh2tmhmcspxVxOKeZySjGbU4rZnMFwpGbzIX9HOgy2JUuWRHt7ezz55JNRW1s71NvhKLBz586YO3durFy5MkaPHj3U2+Eo1NvbG2PGjIkHH3wwpk2bFnPmzIlbbrklHnjggaHeGkeJNWvWxN133x0//elPY8OGDfHEE0/EM888E3fddddQbw3gqGUu58PM5RwOszmlmM2plCF/R/ro0aOjqqoqurq6+l3v6uqKsWPHHvSesWPHlrWeY9tAzsj77rnnnliyZEk899xzce655w7mNhlC5Z6RN954I7Zu3RqXXXZZ37Xe3t6IiBgxYkS89tprMXny5MHdNBUzkO8h48aNixNOOCGqqqr6rn3605+Ozs7O2LNnT1RXVw/qnqmsgZyR733vezF37tz46le/GhER55xzTuzatSuuv/76uOWWW2L4cO9VON4dal4dOXLkUflu9AhzOaWZyynFXE4pZnNKMZszGI7UbD7kJ6m6ujqmTZsWHR0dfdd6e3ujo6MjmpqaDnpPU1NTv/UREc8+++wh13NsG8gZiYhYunRp3HXXXbF69eqYPn16JbbKECn3jEyZMiU2b94cmzZt6ntcfvnlcfHFF8emTZuioaGhkttnkA3ke8iFF14Yr7/+et9f5CIi/va3v8W4ceMM6h9DAzkj77333gED+ft/udv/eTcc747FedVcTinmckoxl1OK2ZxSzOYMhiM2s5b10aSDpL29vaipqSkeeeSR4uWXXy6uv/764tRTTy06OzuLoiiKuXPnFosWLepb/+KLLxYjRowo7rnnnuKVV14pWltbixNOOKHYvHnzUL0EBlm5Z2TJkiVFdXV18Zvf/Kb417/+1ffYuXPnUL0EBlm5Z+TD5s+fX1xxxRUV2i2VVu752LZtW3HKKacU3/jGN4rXXnutePrpp4sxY8YU3//+94fqJTDIyj0jra2txSmnnFL86le/KrZs2VL8/ve/LyZPnlxceeWVQ/USGGQ7d+4sNm7cWGzcuLGIiOLee+8tNm7cWPz9738viqIoFi1aVMydO7dv/ZYtW4qTTjqp+Pa3v1288sorxYoVK4qqqqpi9erVQ/USDou5nFLM5ZRiLqcUszmlmM0pZahm86MipBdFUdx3333F6aefXlRXVxczZswo/vSnP/X9u4suuqiYP39+v/W//vWvizPPPLOorq4uzjrrrOKZZ56p8I6ptHLOyBlnnFFExAGP1tbWym+ciin3+8j/Z2D/+Cv3fLz00ktFY2NjUVNTU0yaNKn4wQ9+UOzbt6/Cu6aSyjkje/fuLW6//fZi8uTJRW1tbdHQ0FDccMMNxX/+85/Kb5yKeP755w86W7x/LubPn19cdNFFB9wzderUorq6upg0aVLx85//vOL7HghzOaWYyynFXE4pZnNKMZuTGarZfFhR+BkHAAAAAAA4lCH/HekAAAAAAHA0E9IBAAAAACAhpAMAAAAAQEJIBwAAAACAhJAOAAAAAAAJIR0AAAAAABJCOgAAAAAAJIR0AAAAAABICOkAAAAAAJAQ0gEAAAAAICGkAwAAAABA4v8An6jWlkX9Nt4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ทดสอบกับภาพนิ่งก่อน\n",
        "def quick_test_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    results = model(img, conf=0.5)\n",
        "    results[0].plot()\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(cv2.cvtColor(results[0].plot(), cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# 2. ปรับ confidence threshold\n",
        "detector.confidence = 0.3  # ลดถ้าต้องการ detect มากขึ้น\n",
        "\n",
        "# 3. ทดสอบ enhancement\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "img = cv2.imread('test.jpg')\n",
        "axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "axes[0].set_title('Original')\n",
        "axes[1].imshow(cv2.cvtColor(processor.enhance_image(img), cv2.COLOR_BGR2RGB))\n",
        "axes[1].set_title('Enhanced')\n",
        "axes[2].imshow(cv2.cvtColor(processor.sharpen_image(img), cv2.COLOR_BGR2RGB))\n",
        "axes[2].set_title('Sharpened')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "weCtR0XTPaNv",
        "outputId": "bb675d4b-76c2-4ec2-844e-9dbd0a3aeb95"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.12.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2517192920.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Original'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menhance_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.12.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nb_wh0ATPaLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c5G4tQnPPaJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RnIfKc0jPaD2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}